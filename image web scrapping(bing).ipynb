{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Scarpping \n",
    "#### For deep learning we need huge ammout of data to train our model, manually getting or downloading those images involves heavy work and time consuming though, this program will help you to download the image by giving apropriate inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bingmagescrapper(keyword,path=None, hd=False):\n",
    "    search = keyword\n",
    "    params = search.replace(' ', \"+\")\n",
    "    dir_name = search.replace(' ', '_')\n",
    "    \n",
    "    if path == None:\n",
    "        os.makedirs('./'+dir_name, exist_ok=True)\n",
    "        loc_path = './'+ dir_name\n",
    "    else:\n",
    "        os.makedirs(path+dir_name, exist_ok=True)\n",
    "        loc_path = path+ dir_name\n",
    "        \n",
    "    \n",
    "    url = \"http://www.bing.com/images/search?q=\" + params + \"&form=HDRSC2&first=1&scenario=ImageBasicHover\"\n",
    "    header = {'User-Agent':\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/43.0.2357.134 Safari/537.36\"}\n",
    "    source = requests.get(url, headers=header).text\n",
    "    \n",
    "    soup = BeautifulSoup(source, 'html.parser')\n",
    "    thumbs =soup.find_all('a', {'class':'iusc'})\n",
    "    if hd == True :\n",
    "        try:\n",
    "            raw_image = []\n",
    "            for index,tag in enumerate(thumbs):\n",
    "                # murl return HD image, High resolution\n",
    "                img_tag_hd = json.loads(tag['m'])\n",
    "                img_raw_hd = img_tag_hd['murl']\n",
    "                raw_image.append(img_raw_hd)\n",
    "                \n",
    "        except:\n",
    "            print(\"Colud not download\")\n",
    "    else:\n",
    "        raw_image = []\n",
    "        for index,tag in enumerate(thumbs):\n",
    "        #turl mostly it is thumb so low resolution\n",
    "            img_tag = json.loads(tag['m'])\n",
    "            img_raw = img_tag['turl']\n",
    "            raw_image.append(img_raw)\n",
    "           \n",
    "    #Saving in our drive\n",
    "    for index,img in enumerate(raw_image):\n",
    "        file_path = os.path.join(loc_path, dir_name+ str(index))\n",
    "        img_temp = requests.get(img).content\n",
    "        img = Image.open(BytesIO(img_temp))\n",
    "        img.save(file_path+'.jpg')\n",
    "        \n",
    "    print(len(raw_image), \"images are downloaded..!\")\n",
    "        \n",
    "        \n",
    "    return raw_image\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
